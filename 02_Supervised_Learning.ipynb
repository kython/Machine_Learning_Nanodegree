{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 监督学习 Supervised Learning\n",
    "## 课程回顾\n",
    "### 监督学习\n",
    "- 样例 Labled Example\n",
    "### 你将看到和学到什么\n",
    "- 佐治亚理工大学的机器学习课程\n",
    "- Mentor：Charles Isabelle &Michael Litman\n",
    "- 神经网络、集成学习（Ensemle Learning）、回归、分类\n",
    "- 课程目标，针对输入数据，选择模型（如何选择也是课程目标），评估模型是否是最优模型。\n",
    "### 机器学习的定义\n",
    "\n",
    "> Machine Learning is the science (and art) of programming computers so they can learn from data.\n",
    "\n",
    "> [Machine Learning is the] field of study that gives computers the ability to learn without being explicitly programmed.\n",
    "—Arthur Samuel, 1959\n",
    "\n",
    "> A computer program is said to learn from experience E with respect to some task T and some performance measure P, if its performance on T, as measured by P, improves with experience E.\n",
    "—Tom Mitchell, 1997\n",
    "\n",
    "- 机器学习体现为越用越好用，即程序完成某任务（`T`）的表现性能（`P`）可以通过经验/数据（`E`）得到提升。\n",
    "- Computational Applied Statistics\n",
    "- 可以不断从经验（数据）中学习并增长知识的的计算构件/人工智能体\n",
    "- Learn better from experience\n",
    "- inductive learing\n",
    "### 监督学习\n",
    "- 函数逼近 Function Approximation\n",
    "### 非监督学习\n",
    "- 与描述有关 Concise Compact Description\n",
    "### 强化学习 Reinforcement Learning\n",
    "- 通过延迟奖赏进行学习。Learning from delayed reward.\n",
    "- multiple agent\n",
    "- game theory\n",
    "### 归纳法与演绎法 Induction & Deduction\n",
    "- 泛化 Generalization\n",
    "- 归纳偏差 Inductive Bias\n",
    "- 归纳：具体到普遍。演绎：从普遍规则到具体事例。\n",
    "### 三种机器学习的比较\n",
    "- 非监督学习可以理解为一种隐藏样例学习（assumed set of labels）的监督学习\n",
    "- supervised learning => labels data well\n",
    "- unsupervised learning => behavior scores well\n",
    "- reinforcement learning => cluster scores well\n",
    "- 人类和机器学习解决问题的不同在于，前者是以算法为中心，后者是以数据为中心"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 决策树\n",
    "### 分类与回归的区别\n",
    "- 分类：离散 discrete\n",
    "- 回归：连续 continuous\n",
    "\n",
    "### 术语\n",
    "- Instance: single input\n",
    "- Concept: function, mapping from input to output, definition\n",
    "- Target concept: target funtion\n",
    "- Hyperthsis: all possible functions\n",
    "- Sample: Traing set, instance paired with label\n",
    "- Candidate concept\n",
    "- Training set $\\neq$ Testing set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20 Question\n",
    "### 决策树学习\n",
    "#### 算法 Algorithm\n",
    "1. Pick best atribute（最佳属性）. best means splitting thing in roughly half.\n",
    "2. Asked question\n",
    "3. Follow the answer path\n",
    "4. go to 1 Until narrow possibility into one item.\n",
    "\n",
    "### 最佳属性测验\n",
    "### 决策树可表达性 AND OR XOR\n",
    "\n",
    "- 决策树可以表达布尔 `AND`、`OR`、`XOR` 操作。\n",
    "- 英语中人们说 `or`的时候，其实是指 `XOR`，二选一，当且仅当只有两个中一个为真才为真。比如：Do you want to go to the movies or go swimming?\n",
    "- n-OR: any. need $n$ node, and the size of decision tree is linear.\n",
    "- n-XOR: Parity (odd, even), the size is $2^n-1$ nodes. exponential problem.\n",
    "- 决策树问题希望最后都转化为n-OR问题，而不是n-XOR。\n",
    "\n",
    "### ID3\n",
    "- best => information gain\n",
    "\n",
    "### ID3 Bias\n",
    "- Inductive Bias\n",
    "    - 限定偏差 restriction bias\n",
    "    - 优选偏差 preference bias\n",
    "- good splits at top of decision tree\n",
    "- prefer correct one over incorrect\n",
    "- prefer shot trees\n",
    "\n",
    "### 决策树连续属性\n",
    "- continous attributes?\n",
    "- $25 \\leq age \\leq 30$\n",
    "\n",
    "### 决策树其他注意事项\n",
    "- when do stop\n",
    "    - everything classified correctly\n",
    "    - no more attribute\n",
    "    - no overfitting\n",
    "    - prunning 剪枝 防止过拟合\n",
    "    - 是否可以在决策树的特定路径上重复某个属性？Yes，当属性为连续性的时候。\n",
    "- 决策树回归\n",
    "    - splitting criteria\n",
    "    \n",
    "### 决策树总结\n",
    "- representation\n",
    "- ID3: a top down learning algorithm\n",
    "- Expression of Decision Trees\n",
    "- Bias of ID3\n",
    "- \"Best\" Attributes\n",
    "- Dealing with overfitting (prune back the trees)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分类和回归\n",
    "\n",
    "### 什么是回归\n",
    "> **Supervised Learing**: Take example of inputs and ouputs. Then given a new input and predict its output\n",
    "\n",
    "- regression: mapping continous inputs to outputs.\n",
    "- regresses to the mean\n",
    "\n",
    "### 回归与函数逼近\n",
    "### 线性回归\n",
    "### 找到最佳拟合\n",
    "### 多项式的阶 Order of pPolynomial\n",
    "### 多项式回归 Polynomial Regression\n",
    "### 误差 Error\n",
    "### 交叉验证\n",
    "- 机器学习的目标是“泛化”。\n",
    "- 训练集和测试集的数据是独立同分布的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 神经网络\n",
    "### 优化权重\n",
    "- momentum\n",
    "- higher oder derivative\n",
    "- randomized optimization\n",
    "- penalty for complexity\n",
    "- more nodes, more layers, large numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 基于实例的学习\n",
    "\n",
    "基于实例的学习是相对通常的基于模型的学习而提出的。\n",
    "\n",
    "> **Instance-based learning**: the system learns the examples by heart, then generalizes to new cases using a similarity measure.\n",
    "\n",
    "> **Model-based learning**: the syetem build a model of these examples, then use that model to make predictions\n",
    "\n",
    "- k-Nearest Neighbors, KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mlnd]",
   "language": "python",
   "name": "conda-env-mlnd-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
